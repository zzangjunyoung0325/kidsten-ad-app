import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

# 1. í”„ë¡œí˜ì…”ë„ ë¹„ì¦ˆë‹ˆìŠ¤ UI ì„¤ì •
st.set_page_config(page_title="KidsTen Growth Intelligence", layout="wide")

st.markdown("""
    <style>
    @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');
    * { font-family: 'Pretendard', sans-serif !important; }
    .main { background-color: #f8fafc; }
    .stMetric { background-color: white; padding: 20px; border-radius: 12px; border: 1px solid #e2e8f0; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
    h1, h2, h3 { color: #1e293b; }
    </style>
    """, unsafe_allow_html=True)

# 2. ë°ì´í„° í†µí•© ë° ë”¥ í´ë Œì§• ì—”ì§„ (InvalidIndexError í•´ê²°)
URL_1 = "https://docs.google.com/spreadsheets/d/1R4qwQFQxXxL7NO67c8mr08KXMZvU9qkArNFoPFKYJDU/export?format=csv&gid=75240363"
URL_2 = "https://docs.google.com/spreadsheets/d/1R4qwQFQxXxL7NO67c8mr08KXMZvU9qkArNFoPFKYJDU/export?format=csv&gid=481757610"

@st.cache_data
def load_and_deep_clean():
    rename_map = {
        'ìº í˜ì¸ ì‹œì‘ì¼': 'ë‚ ì§œ', 'ìº í˜ì¸ ì´ë¦„': 'ìº í˜ì¸ëª…', 
        'ê´‘ê³ ë¹„(ì›)': 'ê´‘ê³ ë¹„', 'ì´ ì „í™˜ ë§¤ì¶œì•¡ (14ì¼)(ì›)': 'ì´ ì „í™˜ë§¤ì¶œì•¡(14ì¼)',
        'í´ë¦­ìˆ˜': 'í´ë¦­ìˆ˜', 'ë…¸ì¶œìˆ˜': 'ë…¸ì¶œìˆ˜'
    }
    
    all_dfs = []
    
    def fetch_strictly(url, name):
        try:
            df = pd.read_csv(url)
            # [ë‹¨ê³„ 1] ì´ë¦„ ì—†ëŠ” ìœ ë ¹ ì»¬ëŸ¼(Unnamed) ì œê±°
            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
            # [ë‹¨ê³„ 2] ì›ë³¸ ìƒíƒœì—ì„œ ì¤‘ë³µ ì´ë¦„ ì œê±°
            df = df.loc[:, ~df.columns.duplicated()].copy()
            # [ë‹¨ê³„ 3] í•­ëª©ëª… ë²ˆì—­
            df = df.rename(columns=rename_map)
            # [ë‹¨ê³„ 4] ë²ˆì—­ í›„ ì¤‘ë³µëœ ì´ë¦„ì´ ìƒê²¼ì„ ê²½ìš°(ì˜ˆ: ë¹„ìš©/ê´‘ê³ ë¹„ ë™ì‹œ ì¡´ì¬) ì²« ë²ˆì§¸ë§Œ ë‚¨ê¹€
            df = df.loc[:, ~df.columns.duplicated()].copy()
            # [ë‹¨ê³„ 5] ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            df = df.reset_index(drop=True)
            return df
        except Exception as e:
            st.warning(f"âš ï¸ {name} ë¡œë”© ì¤‘ ê±´ë„ˆëœ€: {e}")
            return None

    d1 = fetch_strictly(URL_1, "RawData_1")
    d2 = fetch_strictly(URL_2, "RawData_2")

    if d1 is not None: all_dfs.append(d1)
    if d2 is not None: all_dfs.append(d2)
    
    if not all_dfs: return None
    
    # [ë‹¨ê³„ 6] ìˆ˜ì§ í†µí•© ì‹œ indexer ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì»¬ëŸ¼ í•©ì§‘í•©ë§Œ ì¶”ì¶œ
    full_df = pd.concat(all_dfs, axis=0, ignore_index=True, sort=False)
    # [ë‹¨ê³„ 7] ìµœì¢… í†µí•©ë³¸ì—ì„œ í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ì»¬ëŸ¼ ë‹¤ì‹œ í•œ ë²ˆ ì²´í¬
    full_df = full_df.loc[:, ~full_df.columns.duplicated()].copy()
    full_df = full_df.reset_index(drop=True)
    
    # ë°ì´í„° íƒ€ì… ì •ì œ
    full_df['ë‚ ì§œ'] = pd.to_datetime(full_df['ë‚ ì§œ'], errors='coerce')
    for c in ['ê´‘ê³ ë¹„', 'ì´ ì „í™˜ë§¤ì¶œì•¡(14ì¼)', 'í´ë¦­ìˆ˜', 'ë…¸ì¶œìˆ˜']:
        if c in full_df.columns:
            full_df[c] = pd.to_numeric(full_df[c].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    
    full_df['ROAS'] = (full_df['ì´ ì „í™˜ë§¤ì¶œì•¡(14ì¼)'] / full_df['ê´‘ê³ ë¹„'] * 100).replace([float('inf')], 0).fillna(0)
    return full_df

# ë©”ì¸ ì‹¤í–‰
df = load_and_deep_clean()

if df is not None:
    # --- ì‚¬ì´ë“œë°” í•„í„° ---
    with st.sidebar:
        st.header("ğŸ¢ KidsTen Filter")
        if 'ìº í˜ì¸ëª…' in df.columns:
            camps = sorted([x for x in df['ìº í˜ì¸ëª…'].unique() if pd.notna(x)])
            sel_camps = st.multiselect("ìº í˜ì¸ ì„ íƒ", camps, default=camps)
            f_df = df[df['ìº í˜ì¸ëª…'].isin(sel_camps)]
        else: f_df = df
        
        st.divider()
        st.write(f"**ì¥ì¤€ì˜ íŒ€ì¥**")
        st.caption("Growth Lead | 18th Year")

    # --- ë©”ì¸ ëŒ€ì‹œë³´ë“œ ---
    st.title("ğŸš€ ì¿ íŒ¡ í†µí•© ê´‘ê³  ì„±ê³¼ ë¶„ì„")
    
    # í•µì‹¬ ì§€í‘œ
    c1, c2, c3 = st.columns(3)
    c1.metric("ğŸ’° ëˆ„ì  ê´‘ê³ ë¹„", f"{f_df['ê´‘ê³ ë¹„'].sum():,.0f}ì›")
    c2.metric("ğŸ“ˆ ëˆ„ì  ë§¤ì¶œì•¡", f"{f_df['ì´ ì „í™˜ë§¤ì¶œì•¡(14ì¼)'].sum():,.0f}ì›")
    total_roas = (f_df['ì´ ì „í™˜ë§¤ì¶œì•¡(14ì¼)'].sum() / f_df['ê´‘ê³ ë¹„'].sum() * 100) if f_df['ê´‘ê³ ë¹„'].sum() > 0 else 0
    c3.metric("ğŸ¯ í‰ê·  ROAS", f"{total_roas:.1f}%")

    st.divider()

    # íŠ¸ë Œë“œ ì°¨íŠ¸
    st.subheader("ğŸ—“ï¸ ì¼ë³„ ê´‘ê³ ë¹„ ëŒ€ë¹„ ë§¤ì¶œ ì¶”ì´")
    trend = f_df.groupby('ë‚ ì§œ')[['ê´‘ê³ ë¹„', 'ì´ ì „í™˜ë§¤ì¶œì•¡(14ì¼)']].sum().reset_index()
    fig = go.Figure()
    fig.add_trace(go.Bar(x=trend['ë‚ ì§œ'], y=trend['ì´ ì „í™˜ë§¤ì¶œì•¡(14ì¼)'], name='Sales', marker_color='#3b82f6', opacity=0.7))
    fig.add_trace(go.Scatter(x=trend['ë‚ ì§œ'], y=trend['ê´‘ê³ ë¹„'], name='Spend', line=dict(color='#ef4444', width=3)))
    fig.update_layout(template='plotly_white', height=450, margin=dict(l=0,r=0,t=20,b=0))
    st.plotly_chart(fig, use_container_width=True)

    # ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    st.subheader("ğŸ“‹ ì‹¤ì‹œê°„ í†µí•© ë¡œìš°ë°ì´í„°")
    st.dataframe(f_df.sort_values('ë‚ ì§œ', ascending=False), use_container_width=True)

else:
    st.error("ë°ì´í„°ë¥¼ í•©ì¹˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. êµ¬ê¸€ ì‹œíŠ¸ì˜ í•­ëª©ëª…ì´ ì¤‘ë³µë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
