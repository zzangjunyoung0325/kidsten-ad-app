import streamlit as st
import pandas as pd
import numpy as np

# 1. UI ì„¤ì • (êµ°ë”ë”ê¸° ì—†ëŠ” í™”ì´íŠ¸/ë„¤ì´ë¹„ í”„ë¡œí˜ì…”ë„)
st.set_page_config(page_title="KidsTen Strategic Unit", layout="wide")
st.markdown("""
    <style>
    @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');
    * { font-family: 'Pretendard', sans-serif !important; }
    .main { background-color: #f8fafc; }
    .section-title { font-size: 22px; font-weight: 800; color: #1e293b; border-left: 6px solid #2563eb; padding-left: 15px; margin: 30px 0 15px 0; }
    .status-card { background-color: #ffffff; border: 1px solid #e2e8f0; padding: 20px; border-radius: 12px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
    </style>
    """, unsafe_allow_html=True)

# 2. ë°ì´í„° í†µí•© ë° ì „ëµ ì—”ì§„ (InvalidIndexError ì™„ì „ í•´ê²°)
URL_1 = "https://docs.google.com/spreadsheets/d/1R4qwQFQxXxL7NO67c8mr08KXMZvU9qkArNFoPFKYJDU/export?format=csv&gid=75240363"
URL_2 = "https://docs.google.com/spreadsheets/d/1R4qwQFQxXxL7NO67c8mr08KXMZvU9qkArNFoPFKYJDU/export?format=csv&gid=481757610"

@st.cache_data
def load_strategic_intelligence():
    map_cols = {
        'ìº í˜ì¸ ì‹œì‘ì¼': 'ë‚ ì§œ', 'ìº í˜ì¸ ì´ë¦„': 'ìº í˜ì¸ëª…', 
        'ê´‘ê³ ë¹„(ì›)': 'ê´‘ê³ ë¹„', 'ì´ ì „í™˜ ë§¤ì¶œì•¡ (14ì¼)(ì›)': 'ë§¤ì¶œì•¡',
        'ì´ ì£¼ë¬¸ìˆ˜ (14ì¼)': 'ì£¼ë¬¸ìˆ˜', 'í´ë¦­ìˆ˜': 'í´ë¦­ìˆ˜', 'ë…¸ì¶œìˆ˜': 'ë…¸ì¶œìˆ˜'
    }
    
    def fetch_and_clean(url):
        try:
            df = pd.read_csv(url)
            df = df.loc[:, ~df.columns.duplicated()].copy() # ì¤‘ë³µ ì»¬ëŸ¼ ì‚­ì œ
            df = df.rename(columns=map_cols)
            df = df.reset_index(drop=True) # ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            return df
        except: return None

    d1, d2 = fetch_and_clean(URL_1), fetch_and_clean(URL_2)
    dfs = [d for d in [d1, d2] if d is not None]
    if not dfs: return None
    
    full_df = pd.concat(dfs, axis=0, ignore_index=True, sort=False).reset_index(drop=True)
    full_df['ë‚ ì§œ'] = pd.to_datetime(full_df['ë‚ ì§œ'], errors='coerce')
    
    for c in ['ê´‘ê³ ë¹„', 'ë§¤ì¶œì•¡', 'ì£¼ë¬¸ìˆ˜', 'í´ë¦­ìˆ˜', 'ë…¸ì¶œìˆ˜']:
        if c in full_df.columns:
            full_df[c] = pd.to_numeric(full_df[c].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
            
    full_df['ROAS'] = (full_df['ë§¤ì¶œì•¡'] / full_df['ê´‘ê³ ë¹„'] * 100).replace([np.inf, -np.inf], 0).fillna(0)
    full_df['CVR'] = (full_df['ì£¼ë¬¸ìˆ˜'] / full_df['í´ë¦­ìˆ˜'] * 100).replace([np.inf, -np.inf], 0).fillna(0)
    
    return full_df

df = load_strategic_intelligence()

if df is not None:
    # --- ì‚¬ì´ë“œë°”: ë¶„ì„ í”„ë¡œí•„ ---
    with st.sidebar:
        st.title("ğŸ¢ KidsTen Ops")
        st.write("**ì¥ì¤€ì˜ íŒ€ì¥** | Growth Lead")
        st.caption("18th Year Strategic Data Unit")
        st.divider()
        sel_camps = st.multiselect("ìº í˜ì¸ í•„í„°", sorted(df['ìº í˜ì¸ëª…'].unique()), default=df['ìº í˜ì¸ëª…'].unique())
        f_df = df[df['ìº í˜ì¸ëª…'].isin(sel_camps)]

    # --- ë©”ì¸ ë¦¬í¬íŠ¸ ---
    st.markdown('<div class="section-title">ğŸš€ 12ì›” ë°ì´í„° ë¶„ì„ ê¸°ë°˜ 1ì›” ì˜ˆì‚° ìµœì í™” ë¦¬í¬íŠ¸</div>', unsafe_allow_html=True)
    
    # 1. 1ì›” ì „ëµ ì œì–¸ (Actionable Insight)
    st.info(f"""
    **ì „ëµ ë¦¬í¬íŠ¸ ìš”ì•½ (By ì¥ì¤€ì˜ íŒ€ì¥)**
    - **í˜„í™©**: 12ì›” ëŒ€ë¹„ ì¿ íŒ¡ ë‚´ ê²½ìŸ ì…ì°°ê°€ê°€ ì•½ 10% ìƒìŠ¹í•¨. CVRì´ ë‚®ì€ ì¼ë°˜ í‚¤ì›Œë“œì—ì„œ ì˜ˆì‚° ìœ ì‹¤ ì¤‘.
    - **1ì›” ì¡°ì¹˜**: ROAS 250% ë¯¸ë§Œ í‚¤ì›Œë“œëŠ” ì…ì°°ê°€ë¥¼ 20% í•˜í–¥í•˜ê³ , CVR 5% ì´ìƒì¸ íš¨ì í’ˆëª©ì— ì˜ˆì‚°ì˜ 60%ë¥¼ ì§‘ì¤‘ íˆ¬ì…í•˜ì—¬ 'ì´ìµ ê·¹ëŒ€í™”'ë¥¼ ë…¸ë ¤ì•¼ í•¨.
    """)

    # 2. ì´ìƒ ì§•í›„ ì•Œë¦¼ (Anomaly Detection) - ì§€ë‚œì£¼ ëŒ€ë¹„ ê¸‰ë½ í‚¤ì›Œë“œ
    st.markdown('<div class="section-title">ğŸš¨ ì„±ê³¼ ì´ìƒ ì§•í›„ ì•Œë¦¼ (WoW Comparison)</div>', unsafe_allow_html=True)
    max_d = f_df['ë‚ ì§œ'].max()
    curr_week = f_df[f_df['ë‚ ì§œ'] > max_d - pd.Timedelta(days=7)]
    prev_week = f_df[(f_df['ë‚ ì§œ'] <= max_d - pd.Timedelta(days=7)) & (f_df['ë‚ ì§œ'] > max_d - pd.Timedelta(days=14))]
    
    l_sum = curr_week.groupby('í‚¤ì›Œë“œ').agg({'ROAS':'mean', 'ê´‘ê³ ë¹„':'sum', 'CVR':'mean'}).reset_index()
    p_sum = prev_week.groupby('í‚¤ì›Œë“œ').agg({'ROAS':'mean', 'CVR':'mean'}).reset_index()
    
    anomaly = pd.merge(l_sum, p_sum, on='í‚¤ì›Œë“œ', suffixes=('_í˜„ì¬', '_ê³¼ê±°'))
    anomaly['ROAS_ë³€í™”'] = anomaly['ROAS_í˜„ì¬'] - anomaly['ROAS_ê³¼ê±°']
    
    critical = anomaly[(anomaly['ROAS_ë³€í™”'] < -50) & (anomaly['ê´‘ê³ ë¹„'] > 30000)].sort_values('ROAS_ë³€í™”')
    st.warning(f"ì§€ë‚œì£¼ ëŒ€ë¹„ ì„±ê³¼ê°€ ê¸‰ë½í•œ {len(critical)}ê°œì˜ ìœ„í—˜ í‚¤ì›Œë“œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. (ì¦‰ì‹œ ê°ì•¡ ê²€í† )")
    st.dataframe(critical[['í‚¤ì›Œë“œ', 'ROAS_ê³¼ê±°', 'ROAS_í˜„ì¬', 'ROAS_ë³€í™”', 'ê´‘ê³ ë¹„']], use_container_width=True)

    # 3. í‚¤ì›Œë“œë³„ êµ¬ë§¤ ì „í™˜ìœ¨(CVR) ìƒì„¸ ì§„ë‹¨
    st.markdown('<div class="section-title">ğŸ” ì „í™˜ í’ˆì§ˆ(CVR) ë¶„ì„ ë° ì…ì°° ì¡°ì • ëŒ€ìƒ</div>', unsafe_allow_html=True)
    kw_agg = f_df.groupby('í‚¤ì›Œë“œ').agg({'í´ë¦­ìˆ˜':'sum', 'ì£¼ë¬¸ìˆ˜':'sum', 'CVR':'mean', 'ROAS':'mean', 'ê´‘ê³ ë¹„':'sum'}).reset_index()
    
    col1, col2 = st.columns(2)
    with col1:
        st.error("ğŸš« ê´‘ê³ ë¹„ ë„ë‘‘ (í´ë¦­ì€ ë†’ìœ¼ë‚˜ CVR 1% ë¯¸ë§Œ)")
        st.dataframe(kw_agg[(kw_agg['CVR'] < 1) & (kw_agg['í´ë¦­ìˆ˜'] > 100)].sort_values('ê´‘ê³ ë¹„', ascending=False), use_container_width=True)
    with col2:
        st.success("âœ¨ ê³ íš¨ìœ¨ íš¨ì í‚¤ì›Œë“œ (CVR 5% ì´ìƒ)")
        st.dataframe(kw_agg[kw_agg['CVR'] > 5].sort_values('ì£¼ë¬¸ìˆ˜', ascending=False), use_container_width=True)

    # 4. 1ì›” ìº í˜ì¸ë³„ ì˜ì‚¬ê²°ì • ì „ëµí‘œ
    st.markdown('<div class="section-title">ğŸ“‹ ìº í˜ì¸ë³„ 1ì›” ìš´ìš© ê°€ì´ë“œ (Action Item)</div>', unsafe_allow_html=True)
    camp_agg = f_df.groupby('ìº í˜ì¸ëª…').agg({'ê´‘ê³ ë¹„':'sum', 'ë§¤ì¶œì•¡':'sum', 'ROAS':'mean', 'CVR':'mean'}).reset_index()
    
    def get_action(row):
        if row['ROAS'] >= 400 and row['CVR'] >= 3: return "ğŸš€ ê³µê²©ì  ì¦ì•¡ (Scale-up)"
        elif row['ROAS'] < 250: return "â›” ìˆ˜ìµ ë³´í˜¸ (ê°ì•¡)"
        else: return "âš–ï¸ íš¨ìœ¨ ìœ ì§€ (í˜„ìƒìœ ì§€)"
        
    camp_agg['1ì›” ê¶Œì¥ ì•¡ì…˜'] = camp_agg.apply(get_action, axis=1)
    st.dataframe(camp_agg.sort_values('ê´‘ê³ ë¹„', ascending=False), use_container_width=True)

else:
    st.error("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. êµ¬ê¸€ ì‹œíŠ¸ì˜ GIDì™€ ê³µìœ  ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
